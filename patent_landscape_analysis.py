# -*- coding: utf-8 -*-
"""Patent Landscape Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JmIfWm-2l8kgCNbbJcJbE-lGETFMzhYV

# **Patent Landscape Analysis in Electric vs. Hybrid Vehicle Technologies**
*Dissertation (Shaurya Rawat)*

## Importing all the required libraries for the project

Importing essential libraries for data analysis, visualization, NLP, and statistical testing
These libraries enable data manipulation (pandas, numpy), plotting (matplotlib, seaborn),text processing (sklearn, nltk), sentiment analysis (textblob), word clouds (wordcloud),and statistical tests (scipy.stats)
"""

# Importing the essential libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
from scipy.stats import chi2_contingency, ttest_ind
import nltk
from nltk.corpus import stopwords
from wordcloud import WordCloud
from textblob import TextBlob
import uuid

# Downloading NLTK stopwords for text preprocessing, Stopwords are common words (e.g., 'the', 'is') removed to focus on meaningful terms
nltk.download('stopwords')

"""This initial block sets up the environment by importing libraries needed for data processing, visualization, and analysis. It prepares tools for handling patent data, performing NLP tasks like topic modeling, generating visualizations, and conducting statistical tests to compare EV and HEV innovation trends. The NLTK stopwords download ensures text preprocessing can filter out irrelevant words, aligning with the technical professor’s emphasis on advanced NLP.

## Importing the Data
"""

# Load the patent dataset from a the dataset(CSV file), sourced from Google Patents
df = pd.read_csv('DATA.csv')

"""This block reads the patent dataset into a pandas DataFrame, enabling analysis of EV and HEV patents from 2014–2024. The dataset includes critical fields for identifying innovation trends."""

# Display the first few rows
df.head()

# Display the last few rows
df.tail()

df.info()

"""## Data Cleaning, Exploring and Preprocessing

Cleaning critical columns by removing rows with missing title or publication date, Ensures only complete records are analyzed to maintain data integrity.
"""

# 3. Handle missing critical values
df = df.dropna(subset=['title', 'publication_date'])

"""Standardizing publication dates to datetime format and extract year
Converts date strings (YYYYMMDD) to datetime for time-series analysis and drops invalid dates
"""

# 4. Convert and standardize dates
df['publication_date'] = pd.to_datetime(df['publication_date'].astype(str), format='%Y%m%d', errors='coerce')
df = df.dropna(subset=['publication_date'])
df['year'] = df['publication_date'].dt.year

"""Removing duplicate patents based on publication number, Prevents double-counting of identical patents, ensuring accurate trend analysis"""

# 5. Remove duplicate patents
df = df.drop_duplicates(subset=['publication_number'])

"""Imputing missing values in non-critical columns, Filling empty abstracts with '' and assignee/inventor names with 'MIX' to retain records"""

# 6. Fill or impute less critical missing values
df['abstract'] = df['abstract'].fillna('')
df['assignee_names'] = df['assignee_names'].fillna('MIX')
df['inventor_names'] = df['inventor_names'].fillna('MIX')
df['cpc_codes'] = df['cpc_codes'].fillna('')

"""This section prepares the dataset by removing incomplete records, standardizing dates, eliminating duplicates, and imputing missing values. These steps ensure a clean dataset for reliable analysis.

## Feature engineering
Parsing CPC codes into lists for classification, Spliting comma-separated CPC codes into lists for easier processing and Flaging EV and HEV patents using CPC codes, Identifing EV patents (B60L) and HEV patents (B60W) based on CPC codes
"""

# Parse CPC codes
df['cpc_list'] = df['cpc_codes'].str.split(r',\s*')
df['is_ev'] = df['cpc_list'].apply(lambda codes: any(code.startswith('B60L') for code in codes))
df['is_hev'] = df['cpc_list'].apply(lambda codes: any(code.startswith('B60W') for code in codes))

"""Adding keyword-based flags for EV and HEV and Search titles and abstracts for 'electric vehicle' or 'hybrid car' to capture additional patents"""

# Adding keyword filtering
df['is_ev_keyword'] = df['title'].str.lower().str.contains('electric vehicle', na=False) | df['abstract'].str.lower().str.contains('electric vehicle', na=False)
df['is_hev_keyword'] = df['title'].str.lower().str.contains('hybrid car', na=False) | df['abstract'].str.lower().str.contains('hybrid car', na=False)

"""Combining CPC and keyword flags for comprehensive classification and Ensuring patents are correctly categorized as EV or HEV using both methods"""

# Combine CPC and keyword flags
df['is_ev_final'] = df['is_ev'] | df['is_ev_keyword']
df['is_hev_final'] = df['is_hev'] | df['is_hev_keyword']

"""Flaging specific technologies for business factors: Identifing powertrain (B60L9 for EV, B60L11 for HEV), battery (Y02T10/70), autonomous, and connected technology patents using CPC codes and keywords"""

# Add specific technology flags for business factors
df['is_powertrain_ev'] = df['cpc_list'].apply(lambda codes: any(code.startswith('B60L9') for code in codes))
df['is_powertrain_hev'] = df['cpc_list'].apply(lambda codes: any(code.startswith('B60L11') for code in codes))
df['is_battery'] = df['cpc_list'].apply(lambda codes: any(code.startswith('Y02T10/70') for code in codes))
df['is_autonomous'] = df['title'].str.lower().str.contains('autonomous|self-driving', na=False) | df['abstract'].str.lower().str.contains('autonomous|self-driving', na=False)
df['is_connected'] = df['title'].str.lower().str.contains('connected|v2x|iot', na=False) | df['abstract'].str.lower().str.contains('connected|v2x|iot', na=False)

"""Flaging patents related to business factors using keywords

"""

# Keyword flags for business factors
env_keywords = ['emissions', 'carbon', 'sustainability']
cost_keywords = ['cost', 'affordable', 'economical']
maintenance_keywords = ['maintenance', 'durability', 'longevity']
market_keywords = ['commercial', 'market', 'adoption']
regulation_keywords = ['regulation', 'standard', 'compliance']

df['is_environmental'] = df['title'].str.lower().str.contains('|'.join(env_keywords), na=False) | df['abstract'].str.lower().str.contains('|'.join(env_keywords), na=False)
df['is_cost'] = df['title'].str.lower().str.contains('|'.join(cost_keywords), na=False) | df['abstract'].str.lower().str.contains('|'.join(cost_keywords), na=False)
df['is_maintenance'] = df['title'].str.lower().str.contains('|'.join(maintenance_keywords), na=False) | df['abstract'].str.lower().str.contains('|'.join(maintenance_keywords), na=False)
df['is_market'] = df['title'].str.lower().str.contains('|'.join(market_keywords), na=False) | df['abstract'].str.lower().str.contains('|'.join(market_keywords), na=False)
df['is_regulation'] = df['title'].str.lower().str.contains('|'.join(regulation_keywords), na=False) | df['abstract'].str.lower().str.contains('|'.join(regulation_keywords), na=False)

"""This block enhances the dataset by creating features to classify patents and align with the business factors. It parses CPC codes, flags EV and HEV patents using both CPC codes and keywords, and identifies patents related to powertrain, battery, autonomous, and connected technologies. Keyword searches for environmental, cost, and other factors address business considerations.

### Summarize missingness for all columns
Generating a table to assess data quality and ensure robustness of analysis
"""

# Analyzing missingness for all columns
missing_pct = (df.isna().mean() * 100).round(2).reset_index()
missing_pct.columns = ['column', 'percent_missing']
print("Missing Data Summary:")
print(missing_pct)

"""### Visualize missing data pattern"""

# Visualizing missing data pattern
plt.figure(figsize=(10, 5))
sns.heatmap(df.isna(), cbar=False)
plt.title('Missing Data Heatmap')
plt.tight_layout()
plt.savefig('missing_data_heatmap.png')
plt.show()
plt.close()

"""This section evaluates data quality by calculating and displaying the percentage of missing values per column and visualizing missing data patterns with a heatmap. This ensures the dataset is reliable for analysis

### Time-series: patents per year by category
Counting total, EV, and HEV patents per year to track innovation trends
"""

# Patents per year by category
yearly_total = df.groupby('year').size().rename('total')
yearly_ev = df[df['is_ev_final']].groupby('year').size().rename('EV')
yearly_hev = df[df['is_hev_final']].groupby('year').size().rename('HEV')
yearly_counts = pd.concat([yearly_total, yearly_ev, yearly_hev], axis=1).fillna(0).astype(int)

# Visualizing patent filings per year to compare total, EV, and HEV patent trends from 2014–2024
plt.figure(figsize=(10, 5))
plt.plot(yearly_counts.index, yearly_counts['total'], label='Total')
plt.plot(yearly_counts.index, yearly_counts['EV'], label='EV')
plt.plot(yearly_counts.index, yearly_counts['HEV'], label='HEV')
plt.title('Patent Filings per Year (2014–2024)')
plt.xlabel('Year')
plt.ylabel('Number of Patents')
plt.legend()
plt.tight_layout()
plt.savefig('patent_filings_per_year.png')
plt.show()
plt.close()

"""This block analyzes patent filing trends by counting patents per year for total, EV, and HEV categories and plotting them in a line graph

### Powertrain-specific time-series
Counting EV and HEV powertrain patents per year to focus on a key business factor
"""

# Analyzing and Visualizing powertrain specific time-series
yearly_powertrain_ev = df[df['is_powertrain_ev']].groupby('year').size().rename('EV Powertrain')
yearly_powertrain_hev = df[df['is_powertrain_hev']].groupby('year').size().rename('HEV Powertrain')
yearly_powertrain = pd.concat([yearly_powertrain_ev, yearly_powertrain_hev], axis=1).fillna(0).astype(int)
yearly_powertrain.plot(kind='line', figsize=(10, 5))
plt.title('Powertrain-Related Patent Filings Over Time')
plt.xlabel('Year')
plt.ylabel('Number of Patents')
plt.legend()
plt.tight_layout()
plt.savefig('powertrain_patents_over_time.png')
plt.show()
plt.close()

"""This section focuses on powertrain technology, a key business factor, by counting and visualizing EV and HEV powertrain patents over time. It uses specific CPC codes to isolate powertrain innovations, addressing the business emphasis on powertrain technology and providing insights into a critical area of EV and HEV development

### Battery-specific time-series
Counting battery patents per year to address battery and charging infrastructure
"""

# Analyzing and Visualizing battery specific time-series
yearly_battery = df[df['is_battery']].groupby('year').size().rename('Battery')
yearly_battery.plot(kind='line', figsize=(10, 5))
plt.title('Battery-Related Patent Filings Over Time')
plt.xlabel('Year')
plt.ylabel('Number of Patents')
plt.tight_layout()
plt.savefig('battery_patents_over_time.png')
plt.show()
plt.close()

"""This block examines battery and charging infrastructure, another business factor, by counting and plotting battery-related patents over time. It uses CPC codes to identify battery innovations, addressing the business focus on this area and highlighting its role in EV growth

### Autonomous and connected technologies
Counting patents related to autonomous and connected technologies per year
"""

# Analyzing and Visualizing autonomous and connected technology patents
yearly_autonomous = df[df['is_autonomous']].groupby('year').size().rename('Autonomous')
yearly_connected = df[df['is_connected']].groupby('year').size().rename('Connected')
yearly_tech = pd.concat([yearly_autonomous, yearly_connected], axis=1).fillna(0).astype(int)
yearly_tech.plot(kind='line', figsize=(10, 5))
plt.title('Autonomous and Connected Technology Patent Filings')
plt.xlabel('Year')
plt.ylabel('Number of Patents')
plt.legend()
plt.tight_layout()
plt.savefig('autonomous_connected_patents.png')
plt.show()
plt.close()

"""This section analyzes patents related to autonomous and connected technologies, addressing the business factor on innovation in these areas. It counts and visualizes patents over time, using keyword searches to identify relevant innovations, providing insights into smart vehicle trends

### Keyword-based analysis for business factors
Calculating the proportion of EV and HEV patents mentioning environmental, cost, etc
"""

# Analyzing and Calculating business factors
business_factors = {
    'Environmental': df['is_environmental'],
    'Cost': df['is_cost'],
    'Maintenance': df['is_maintenance'],
    'Market': df['is_market'],
    'Regulation': df['is_regulation']
}

for factor, condition in business_factors.items():
    ev_prop = df[df['is_ev_final'] & condition].shape[0] / df[df['is_ev_final']].shape[0] if df[df['is_ev_final']].shape[0] > 0 else 0
    hev_prop = df[df['is_hev_final'] & condition].shape[0] / df[df['is_hev_final']].shape[0] if df[df['is_hev_final']].shape[0] > 0 else 0
    print(f"Proportion of EV patents mentioning {factor}: {ev_prop:.2f}")
    print(f"Proportion of HV patents mentioning {factor}: {hev_prop:.2f}")

# Visualizing business factor proportions
factor_data = []
for factor, condition in business_factors.items():
    factor_data.append({
        'Factor': factor,
        'EV': df[df['is_ev_final'] & condition].shape[0] / df[df['is_ev_final']].shape[0] if df[df['is_ev_final']].shape[0] > 0 else 0,
        'HEV': df[df['is_hev_final'] & condition].shape[0] / df[df['is_hev_final']].shape[0] if df[df['is_hev_final']].shape[0] > 0 else 0
    })
factor_df = pd.DataFrame(factor_data)
factor_df.set_index('Factor')[['EV', 'HEV']].plot(kind='bar', figsize=(12, 6))
plt.title('Proportion of Patents Mentioning Business Factors')
plt.ylabel('Proportion')
plt.tight_layout()
plt.savefig('business_factors_bar.png')
plt.show()
plt.close()

"""This block addresses the business factors (environmental impact, cost, maintenance, market, regulation) by calculating and visualizing the proportion of EV and HEV patents mentioning relevant keywords

### Text preprocessing for topic modeling
Converting abstracts to a document-term matrix, removing common words for LDA
"""

stop_words = stopwords.words('english')
vectorizer = CountVectorizer(max_df=0.95, min_df=20, stop_words=stop_words)
dtm = vectorizer.fit_transform(df['abstract'].str.lower())

"""### Modeling : Latent Dirichlet Allocation (LDA)
Extracting latent themes from patent abstracts to identify sub-technologies
"""

n_topics = 8
lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)
lda.fit(dtm)

"""Identifing the most representative words to describe each topic"""

# Extract top words for each topic
topics = []
feature_names = vectorizer.get_feature_names_out()
for idx, comp in enumerate(lda.components_):
    top_indices = comp.argsort()[-10:][::-1]
    topics.append([feature_names[i] for i in top_indices])

topic_df = pd.DataFrame(topics, columns=[f'Word{i+1}' for i in range(10)])
topic_df.insert(0, 'Topic', range(n_topics))
print("Top Words per Topic:")
print(topic_df)

"""This section applies NLP to patent abstracts using LDA to identify eight sub-technologies. It preprocesses text by removing stopwords and converting abstracts to a document-term matrix, then extracts and displays top words per topic

### Word clouds for each topic
Visualizing top words as word clouds to illustrate thematic content
"""

# Visualize Word clouds for each topic
fig, axes = plt.subplots(2, 4, figsize=(15, 10))
axes = axes.flatten()
for i, words in enumerate(topics):
    wc = WordCloud(background_color='white').generate(' '.join(words))
    axes[i].imshow(wc, interpolation='bilinear')
    axes[i].axis('off')
    axes[i].set_title(f'Topic {i}')
plt.tight_layout()
plt.savefig('topic_word_clouds.png')
plt.show()
plt.close()

"""This block creates word clouds for each LDA topic, visually representing the most prominent words. It aids in interpreting sub-technologies

### Topic distribution counts
Counting patents per topic per year to track sub-technology evolution
"""

# Identify and Visualize topic trends
df['topic'] = lda.transform(dtm).argmax(axis=1)
yearly_topics = df.groupby(['year', 'topic']).size().unstack(fill_value=0)
yearly_topics.plot(kind='line', figsize=(10, 5))
plt.title('Topic Distribution Over Time')
plt.xlabel('Year')
plt.ylabel('Number of Patents')
plt.legend(title='Topic')
plt.tight_layout()
plt.savefig('topic_distribution_over_time.png')
plt.show()
plt.close()

"""This section examines how sub-technologies evolve by counting patents per topic per year and plotting trends

### Top 10 assignees
Counting patents per assignee to identify leading companies
"""

# Identify and Visualize top assignees
df['assignee_list'] = df['assignee_names'].str.split(r',\s*')
assignees = df.explode('assignee_list')
top_assignees = assignees['assignee_list'].value_counts().head(10)
print("Top 10 Patent Assignees:")
print(top_assignees.rename('count').reset_index().rename(columns={'index': 'assignee'}))
plt.figure(figsize=(10, 5))
sns.barplot(x=top_assignees.values, y=top_assignees.index)
plt.title('Top 10 Patent Assignees')
plt.xlabel('Number of Patents')
plt.ylabel('Assignee')
plt.tight_layout()
plt.savefig('top_assignees.png')
plt.show()
plt.close()

"""This block identifies the top 10 patent assignees and visualizes their patent counts in a bar chart

### Statistical tests
"""

# Chi-square test for topic distribution
ev_topics = pd.Series(df['topic'][df['is_ev_final']]).value_counts().sort_index()
hev_topics = pd.Series(df['topic'][df['is_hev_final']]).value_counts().sort_index()
ev_topics = ev_topics.reindex(range(n_topics), fill_value=0)
hev_topics = hev_topics.reindex(range(n_topics), fill_value=0)
contingency = pd.DataFrame({'EV': ev_topics, 'HEV': hev_topics})
chi2, p, dof, expected = chi2_contingency(contingency.values)
print(f"Chi-square statistic: {chi2:.2f}, p-value: {p:.4f}")

# T-test for comparing mean patent counts
ev_counts = yearly_counts['EV']
hev_counts = yearly_counts['HEV']
t_stat, p_value = ttest_ind(ev_counts, hev_counts)
print(f'T-test: t-statistic = {t_stat:.2f}, p-value = {p_value:.4f}')

"""This final block conducts statistical tests to validate differences in EV and HEV innovation. The Chi-square test (statistic: 27427.68, p-value: 0.0000) confirms distinct topic distributions, indicating different sub-technologies. The T-test (t-statistic: 9.19, p-value: 0.0000) shows higher EV patent counts, suggesting faster innovation."""